{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal \n",
    "\n",
    "**Inputs:**\n",
    "\n",
    "1. Take an input context text \n",
    "2. Take input sentence\n",
    "\n",
    "**Backend:**\n",
    "\n",
    "1. Convert input(1) to tokens \n",
    "2. wikpedia_topic_mode(tokens) -> likely_topics\n",
    "3. wikpedia_topic_mode(likely_topics) -> pun_possible_words\n",
    "4. pun.insert_pun( input(2), pun_possible_words ) -> new sentence\n",
    "\n",
    "**Output:**\n",
    "\n",
    "1. Print new sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pun\n",
    "import pickle\n",
    "from gensim.models.ldamodel import LdaModel as Lda\n",
    "from gensim import corpora\n",
    "from gensim.models import doc2vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmvoje/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['love',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.0726928659579519,\n",
       "  0.3632044792175293,\n",
       "  0.2001430877575023],\n",
       " ['make',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.030784627488728136,\n",
       "  0.3632044792175293,\n",
       "  0.08475839162294775],\n",
       " ['move',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.055041541776322055,\n",
       "  0.3632044792175293,\n",
       "  0.15154422625761932],\n",
       " ['include',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.04130730505567569,\n",
       "  0.3632044792175293,\n",
       "  0.11373016418923634],\n",
       " ['music',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.05459013115835901,\n",
       "  0.3632044792175293,\n",
       "  0.1503013709411443],\n",
       " ['soul',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.20526952865968637,\n",
       "  0.3632044792175293,\n",
       "  0.5651624371536095],\n",
       " ['die',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.043342488171534826,\n",
       "  0.3632044792175293,\n",
       "  0.11933357282627641],\n",
       " ['bear',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.046323525499532496,\n",
       "  0.3632044792175293,\n",
       "  0.12754117349909816],\n",
       " ['singer',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.07031166939533748,\n",
       "  0.3632044792175293,\n",
       "  0.19358701067457548],\n",
       " ['songwriter',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.09109644738676159,\n",
       "  0.3632044792175293,\n",
       "  0.25081311657558714],\n",
       " ['song',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.07028993785232451,\n",
       "  0.3632044792175293,\n",
       "  0.19352717786893447],\n",
       " ['woman',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.07832334307797532,\n",
       "  0.3632044792175293,\n",
       "  0.2156453115520807],\n",
       " ['raise',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.0783065814194477,\n",
       "  0.3632044792175293,\n",
       "  0.21559916218034458],\n",
       " ['hit',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.15031261910894025,\n",
       "  0.3632044792175293,\n",
       "  0.4138512262645183],\n",
       " ['pneumonia',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.10433451468091255,\n",
       "  0.3632044792175293,\n",
       "  0.2872610902422953],\n",
       " ['single',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.08877257833702447,\n",
       "  0.3632044792175293,\n",
       "  0.24441487761459316],\n",
       " ['people',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.06120145922640553,\n",
       "  0.3564869463443756,\n",
       "  0.1716793836464445],\n",
       " ['live',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.08871371365920384,\n",
       "  0.3564869463443756,\n",
       "  0.24885543375129396],\n",
       " ['population',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.1259539417537687,\n",
       "  0.3564869463443756,\n",
       "  0.35331992670523743],\n",
       " ['province',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.13417211107467003,\n",
       "  0.3564869463443756,\n",
       "  0.3763731391865785],\n",
       " ['municipality',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.15046822626844017,\n",
       "  0.3564869463443756,\n",
       "  0.42208621609130104],\n",
       " ['commune',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.14771385157093292,\n",
       "  0.3564869463443756,\n",
       "  0.41435977694464443],\n",
       " ['par',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.19271891815660883,\n",
       "  0.3564869463443756,\n",
       "  0.5406058205857484],\n",
       " ['group', 'doc2vec', 4, 0.35091739892959595, 0.35091739892959595, 1.0],\n",
       " ['person',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.0623075523533353,\n",
       "  0.35071125626564026,\n",
       "  0.17766054336773698],\n",
       " ['run',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.06240999768061293,\n",
       "  0.35071125626564026,\n",
       "  0.17795265069377056],\n",
       " ['university',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.05508998898171081,\n",
       "  0.35071125626564026,\n",
       "  0.15708075517252243],\n",
       " ['play',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.0474630892858158,\n",
       "  0.35071125626564026,\n",
       "  0.13533380648001128],\n",
       " ['college',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.07311525761888855,\n",
       "  0.35071125626564026,\n",
       "  0.20847707711870145],\n",
       " ['football',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.2050927439150094,\n",
       "  0.35071125626564026,\n",
       "  0.5847908792515784],\n",
       " ['league',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.07174132615025536,\n",
       "  0.35071125626564026,\n",
       "  0.2045595197432617],\n",
       " ['cardinals',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.13337866965670042,\n",
       "  0.35071125626564026,\n",
       "  0.3803090641484145],\n",
       " ['draft',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.19896716500381395,\n",
       "  0.35071125626564026,\n",
       "  0.567324719264527]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pun.generate_possible_pun_substitutions(\"I love my dog and think that she's a very sweet and caring person.\",\n",
    "                                                 'This is just a test')\n",
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pun.sentence_to_doc2vec(\"This is a short sentence\",\n",
    "                        pun.wiki_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([('regions', 0.43092002529087925), ('department', 0.3812470718185651), ('region', 0.34970959120588385), ('saint', 0.40115568200282054), ('commune', 0.41759641521331237), ('departments', 0.4597272633306995)], 0.6495630741119385, 56293)\n",
      "([('regions', 0.43092002529087925), ('department', 0.3812470718185651), ('region', 0.34970959120588385), ('saint', 0.40115568200282054), ('commune', 0.41759641521331237), ('departments', 0.4597272633306995)], 0.5927094221115112, 56281)\n",
      "([('regions', 0.3915072128851519), ('department', 0.346377447665742), ('region', 0.3177244484746374), ('saint', 0.364465176311895), ('martin', 0.4178022544953132), ('commune', 0.37940220698871985), ('departments', 0.41767968298160685)], 0.59075927734375, 55378)\n",
      "([('regions', 0.3915072128851519), ('department', 0.346377447665742), ('region', 0.3177244484746374), ('saint', 0.364465176311895), ('martin', 0.4178022544953132), ('commune', 0.37940220698871985), ('departments', 0.41767968298160685)], 0.5778038501739502, 56302)\n",
      "([('part', 0.1318152105776549), ('regions', 0.25720657910423056), ('department', 0.22755789794119258), ('region', 0.20873387718124245), ('commune', 0.7477620377287162), ('departments', 0.2744009787951289), ('pas', 0.4320568658121436)], 0.525965690612793, 55747)\n",
      "([('regions', 0.43092002529087925), ('department', 0.3812470718185651), ('region', 0.34970959120588385), ('saint', 0.40115568200282054), ('commune', 0.41759641521331237), ('departments', 0.4597272633306995)], 0.4408355951309204, 56312)\n",
      "([('city', 0.19702735887078104), ('part', 0.1789617832269102), ('state', 0.29685744575827694), ('unite', 0.3004397915457802), ('population', 0.2885542467122063), ('seat', 0.7232666618866603), ('census', 0.3799819351786699)], 0.44032350182533264, 129363)\n",
      "([('number', 0.192228757343597), ('performance', 0.3024419001272685), ('album', 0.4900578380972063), ('release', 0.38321477600861664), ('award', 0.22579532738331837), ('song', 0.2486160436702256), ('pop', 0.307345236134846), ('nominate', 0.3246813155502245), ('soundtrack', 0.414601296169124)], 0.4301551580429077, 110467)\n",
      "([('cities', 0.6084954004759123), ('list', 0.4924809274595465), ('municipality', 0.6222506598536026)], 0.4299221932888031, 11046)\n",
      "([('file', 1.0)], 0.4239669442176819, 135019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmvoje/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sasamuta',\n",
       " 'was',\n",
       " 'the',\n",
       " 'chief',\n",
       " 'shinto',\n",
       " 'shrine',\n",
       " 'of',\n",
       " 'the',\n",
       " 'old',\n",
       " 'bungo',\n",
       " 'province',\n",
       " 'it',\n",
       " 'serves',\n",
       " 'today',\n",
       " 'as',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ichinomiya',\n",
       " 'of',\n",
       " 'oita',\n",
       " 'prefecture',\n",
       " 'nationwide',\n",
       " 'list',\n",
       " 'of',\n",
       " 'ichinomiya',\n",
       " 'retrieved',\n",
       " 'this',\n",
       " 'place',\n",
       " 'is',\n",
       " 'special',\n",
       " 'to',\n",
       " 'the',\n",
       " 'kami',\n",
       " 'named']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pun.wiki_doc2vec_corpus[99662]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379626</td>\n",
       "      <td>0.379626</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.063716</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.171679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>live</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.248855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>population</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.131130</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.353320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>province</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139686</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.376373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>municipality</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156651</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.422086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>commune</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153784</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.414360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>par</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200638</td>\n",
       "      <td>0.371136</td>\n",
       "      <td>0.540606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>head</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.064088</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.174386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.034093</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.092770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mother</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071362</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.194181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>children</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058218</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.158414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>death</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.056966</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.155008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iii</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.085681</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.233143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>john</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.226766</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.617042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fell</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.092426</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.251496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>senator</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.091945</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.250188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>marry</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.061386</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.167033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>candidate</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.096470</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>twin</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.097954</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.266537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sister</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.086032</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.234097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wright</td>\n",
       "      <td>doc2vec</td>\n",
       "      <td>5</td>\n",
       "      <td>0.110597</td>\n",
       "      <td>0.367504</td>\n",
       "      <td>0.300939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1  2         3         4         5\n",
       "0          group  doc2vec  1  0.379626  0.379626  1.000000\n",
       "1         people  doc2vec  2  0.063716  0.371136  0.171679\n",
       "2           live  doc2vec  2  0.092359  0.371136  0.248855\n",
       "3     population  doc2vec  2  0.131130  0.371136  0.353320\n",
       "4       province  doc2vec  2  0.139686  0.371136  0.376373\n",
       "5   municipality  doc2vec  2  0.156651  0.371136  0.422086\n",
       "6        commune  doc2vec  2  0.153784  0.371136  0.414360\n",
       "7            par  doc2vec  2  0.200638  0.371136  0.540606\n",
       "8           head  doc2vec  5  0.064088  0.367504  0.174386\n",
       "9           time  doc2vec  5  0.034093  0.367504  0.092770\n",
       "10        mother  doc2vec  5  0.071362  0.367504  0.194181\n",
       "11      children  doc2vec  5  0.058218  0.367504  0.158414\n",
       "12         death  doc2vec  5  0.056966  0.367504  0.155008\n",
       "13           iii  doc2vec  5  0.085681  0.367504  0.233143\n",
       "14          john  doc2vec  5  0.226766  0.367504  0.617042\n",
       "15          fell  doc2vec  5  0.092426  0.367504  0.251496\n",
       "16       senator  doc2vec  5  0.091945  0.367504  0.250188\n",
       "17         marry  doc2vec  5  0.061386  0.367504  0.167033\n",
       "18     candidate  doc2vec  5  0.096470  0.367504  0.262500\n",
       "19          twin  doc2vec  5  0.097954  0.367504  0.266537\n",
       "20        sister  doc2vec  5  0.086032  0.367504  0.234097\n",
       "21        wright  doc2vec  5  0.110597  0.367504  0.300939"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "print(len(output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_topic_words_to_print(topic_words):\n",
    "    output = [[]]\n",
    "    topic_number = 1\n",
    "    for topic in topic_words:\n",
    "        if topic[1] == 'topicModel':\n",
    "            return output\n",
    "        if topic[2] != topic_number:\n",
    "            topic_number = topic[2]\n",
    "            output.append([topic[0]])\n",
    "        output[topic_number-1].append(topic[0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = output[1]\n",
    "\n",
    "\n",
    "test.sort(key=lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cat',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.3732185934559639,\n",
       "  0.41739949584007263,\n",
       "  0.8941519986860821],\n",
       " ['ferret',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.32527786657376184,\n",
       "  0.3852998614311218,\n",
       "  0.8442200455654982],\n",
       " ['catfish',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.31355886929641774,\n",
       "  0.39072367548942566,\n",
       "  0.8025079844564058],\n",
       " ['formulas',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.17813471769931302,\n",
       "  0.3824636936187744,\n",
       "  0.46575588917695043],\n",
       " ['hunt',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.12668919316311963,\n",
       "  0.3852998614311218,\n",
       "  0.3288067446807718],\n",
       " ['barbel',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.1158402332885402,\n",
       "  0.39072367548942566,\n",
       "  0.29647610461136553],\n",
       " ['whisker',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.09023460350423076,\n",
       "  0.39072367548942566,\n",
       "  0.23094224682239103],\n",
       " ['diverse',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.07891399331449649,\n",
       "  0.39072367548942566,\n",
       "  0.20196880369649414],\n",
       " ['aquarium',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.07627673721146928,\n",
       "  0.39072367548942566,\n",
       "  0.19521913310199088],\n",
       " ['can',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.074773843566463,\n",
       "  0.3824636936187744,\n",
       "  0.1955057298614984],\n",
       " ['felines',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.07032045742781945,\n",
       "  0.41739949584007263,\n",
       "  0.16847278956648012],\n",
       " ['order',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.06835520025330477,\n",
       "  0.39072367548942566,\n",
       "  0.17494511989242048],\n",
       " ['thin',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.06748611334246475,\n",
       "  0.3852998614311218,\n",
       "  0.1751521869013932],\n",
       " ['taste',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.06614344203975304,\n",
       "  0.37984365224838257,\n",
       "  0.17413333525052924],\n",
       " ['rodent',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.062250302495632334,\n",
       "  0.3852998614311218,\n",
       "  0.16156326208998784],\n",
       " ['domesticate',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.06210320150602387,\n",
       "  0.3852998614311218,\n",
       "  0.16118147895344043],\n",
       " ['meat',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.058557943775646826,\n",
       "  0.3824636936187744,\n",
       "  0.15310719619315083],\n",
       " ['rabbit',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.056051161042958556,\n",
       "  0.3852998614311218,\n",
       "  0.14547412717660307],\n",
       " ['mummify',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.05129049515505121,\n",
       "  0.37984365224838257,\n",
       "  0.1350305444133419],\n",
       " ['mummification',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.0510326944330822,\n",
       "  0.37984365224838257,\n",
       "  0.13435184221457397],\n",
       " ['families',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.050970894780244205,\n",
       "  0.39072367548942566,\n",
       "  0.13045253711948063],\n",
       " ['farm',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.04800886214013858,\n",
       "  0.39072367548942566,\n",
       "  0.12287164856340493],\n",
       " ['hole',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.04695091730833585,\n",
       "  0.3852998614311218,\n",
       "  0.1218555260672707],\n",
       " ['pet',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.04662003408545626,\n",
       "  0.41739949584007263,\n",
       "  0.1116916396643632],\n",
       " ['eternity',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.04652916811635707,\n",
       "  0.37984365224838257,\n",
       "  0.12249557901241774],\n",
       " ['organs',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.04541452814105399,\n",
       "  0.41739949584007263,\n",
       "  0.10880350502017531],\n",
       " ['call',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.04398741002387689,\n",
       "  0.41739949584007263,\n",
       "  0.10538443496522752],\n",
       " ['nutrient',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.043582222603238886,\n",
       "  0.3824636936187744,\n",
       "  0.11395126735004558],\n",
       " ['scrap',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.04239437200112774,\n",
       "  0.37984365224838257,\n",
       "  0.11161005784929044],\n",
       " ['today',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.041418821949562826,\n",
       "  0.37984365224838257,\n",
       "  0.10904176416900803],\n",
       " ['keep',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.04094176863641255,\n",
       "  0.41739949584007263,\n",
       "  0.09808772900890006],\n",
       " ['kitten',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.04091644608771656,\n",
       "  0.3824636936187744,\n",
       "  0.10698125539858576],\n",
       " ['food',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.040564188225031404,\n",
       "  0.39072367548942566,\n",
       "  0.10381809644429701],\n",
       " ['essence',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.0403405876232065,\n",
       "  0.3824636936187744,\n",
       "  0.10547560015831593],\n",
       " ['breed',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.03983247405761962,\n",
       "  0.41739949584007263,\n",
       "  0.09543009623778152],\n",
       " ['mice',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.03897284574017199,\n",
       "  0.37984365224838257,\n",
       "  0.10260233522261776],\n",
       " ['salmon',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.03891777627909506,\n",
       "  0.3824636936187744,\n",
       "  0.10175547882954572],\n",
       " ['past',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.0384603434350155,\n",
       "  0.37984365224838257,\n",
       "  0.10125308981039913],\n",
       " ['moist',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.038045993747055994,\n",
       "  0.3824636936187744,\n",
       "  0.09947609245487972],\n",
       " ['ancestors',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.03701245583245879,\n",
       "  0.37984365224838257,\n",
       "  0.0974412909452968],\n",
       " ['grow',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.036790974935999574,\n",
       "  0.39072367548942566,\n",
       "  0.09416110986853998],\n",
       " ['diet',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.036494767470225675,\n",
       "  0.3824636936187744,\n",
       "  0.09542021394219526],\n",
       " ['look',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.03630103098641701,\n",
       "  0.39072367548942566,\n",
       "  0.09290717011439313],\n",
       " ['sex',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.03588026096288287,\n",
       "  0.41739949584007263,\n",
       "  0.08596143819165142],\n",
       " ['bag',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.034530094945343356,\n",
       "  0.3824636936187744,\n",
       "  0.09028332759804822],\n",
       " ['foods',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.034200182819552054,\n",
       "  0.37984365224838257,\n",
       "  0.09003752627459548],\n",
       " ['hairless',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.034089861056232976,\n",
       "  0.41739949584007263,\n",
       "  0.08167202259701475],\n",
       " ['remove',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.033804954328510925,\n",
       "  0.41739949584007263,\n",
       "  0.08098944695770154],\n",
       " ['vegetables',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.0337696884461198,\n",
       "  0.3824636936187744,\n",
       "  0.08829514803509735],\n",
       " ['flavor',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.03374762260099364,\n",
       "  0.3824636936187744,\n",
       "  0.08823745407487492],\n",
       " ['insects',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.03307172101987652,\n",
       "  0.37984365224838257,\n",
       "  0.08706666762526462],\n",
       " ['puma',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.032905002467893574,\n",
       "  0.41739949584007263,\n",
       "  0.07883335460592215],\n",
       " ['pussycat',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.03242937774345444,\n",
       "  0.41739949584007263,\n",
       "  0.07769385940005978],\n",
       " ['gods',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.0321760872124175,\n",
       "  0.37984365224838257,\n",
       "  0.08470876641470716],\n",
       " ['lynx',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.031285331209599504,\n",
       "  0.41739949584007263,\n",
       "  0.07495296837058599],\n",
       " ['furry',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.030970721777765567,\n",
       "  0.41739949584007263,\n",
       "  0.07419923139924456],\n",
       " ['owners',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.030925667908148387,\n",
       "  0.3824636936187744,\n",
       "  0.08085909440328196],\n",
       " ['wildcat',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.030774852256867307,\n",
       "  0.41739949584007263,\n",
       "  0.07372996988156101],\n",
       " ['body',\n",
       "  'doc2vec',\n",
       "  3,\n",
       "  0.03043237077024914,\n",
       "  0.3852998614311218,\n",
       "  0.07898360164785417],\n",
       " ['milk',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.0304247898329817,\n",
       "  0.3824636936187744,\n",
       "  0.07954948493309276],\n",
       " ['cheetah',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.03041157254647176,\n",
       "  0.41739949584007263,\n",
       "  0.07285962932289695],\n",
       " ['people',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.030399837592620257,\n",
       "  0.37984365224838257,\n",
       "  0.08003250130067088],\n",
       " ['jaguar',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.0300022964329154,\n",
       "  0.41739949584007263,\n",
       "  0.07187909121100336],\n",
       " ['ability',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.02983108016538501,\n",
       "  0.37984365224838257,\n",
       "  0.07853515515872896],\n",
       " ['tame',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.02963361271044201,\n",
       "  0.41739949584007263,\n",
       "  0.07099580379415739],\n",
       " ['leopard',\n",
       "  'doc2vec',\n",
       "  1,\n",
       "  0.02949579467100714,\n",
       "  0.41739949584007263,\n",
       "  0.07066562122132632],\n",
       " ['feed',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.028874229231845527,\n",
       "  0.3824636936187744,\n",
       "  0.07549534691422576],\n",
       " ['manufacture',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.028737565065785675,\n",
       "  0.3824636936187744,\n",
       "  0.07513802105992892],\n",
       " ['compare',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.028634198484188238,\n",
       "  0.37984365224838257,\n",
       "  0.07538417007812499],\n",
       " ['group',\n",
       "  'doc2vec',\n",
       "  2,\n",
       "  0.02845613720107994,\n",
       "  0.39072367548942566,\n",
       "  0.072829313876195],\n",
       " ['evidence',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.028314497283244942,\n",
       "  0.37984365224838257,\n",
       "  0.0745425048323037],\n",
       " ['weight',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.02781287378467501,\n",
       "  0.3824636936187744,\n",
       "  0.07272029802755042],\n",
       " ['come',\n",
       "  'doc2vec',\n",
       "  4,\n",
       "  0.027679821251932253,\n",
       "  0.3824636936187744,\n",
       "  0.07237241524818423],\n",
       " ['ancient',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.027593625055793502,\n",
       "  0.37984365224838257,\n",
       "  0.0726446918158575],\n",
       " ['kinds',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.026909058465581698,\n",
       "  0.37984365224838257,\n",
       "  0.0708424592758119],\n",
       " ['rat',\n",
       "  'doc2vec',\n",
       "  5,\n",
       "  0.026792127865534327,\n",
       "  0.37984365224838257,\n",
       "  0.07053462051279656]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['call',\n",
       "  'sex',\n",
       "  'keep',\n",
       "  'breed',\n",
       "  'remove',\n",
       "  'organs',\n",
       "  'cat',\n",
       "  'leopard',\n",
       "  'pet',\n",
       "  'cheetah',\n",
       "  'felines',\n",
       "  'furry',\n",
       "  'hairless',\n",
       "  'jaguar',\n",
       "  'lynx',\n",
       "  'puma',\n",
       "  'pussycat',\n",
       "  'tame',\n",
       "  'wildcat'],\n",
       " ['look',\n",
       "  'look',\n",
       "  'group',\n",
       "  'order',\n",
       "  'farm',\n",
       "  'food',\n",
       "  'grow',\n",
       "  'families',\n",
       "  'diverse',\n",
       "  'aquarium',\n",
       "  'whisker',\n",
       "  'barbel',\n",
       "  'catfish'],\n",
       " ['hunt',\n",
       "  'hunt',\n",
       "  'body',\n",
       "  'hole',\n",
       "  'domesticate',\n",
       "  'thin',\n",
       "  'rodent',\n",
       "  'rabbit',\n",
       "  'ferret'],\n",
       " ['come',\n",
       "  'come',\n",
       "  'weight',\n",
       "  'flavor',\n",
       "  'vegetables',\n",
       "  'meat',\n",
       "  'feed',\n",
       "  'salmon',\n",
       "  'owners',\n",
       "  'milk',\n",
       "  'formulas',\n",
       "  'manufacture',\n",
       "  'bag',\n",
       "  'can',\n",
       "  'nutrient',\n",
       "  'essence',\n",
       "  'moist',\n",
       "  'diet',\n",
       "  'kitten'],\n",
       " ['people',\n",
       "  'people',\n",
       "  'ancient',\n",
       "  'scrap',\n",
       "  'foods',\n",
       "  'taste',\n",
       "  'today',\n",
       "  'rat',\n",
       "  'compare',\n",
       "  'ancestors',\n",
       "  'gods',\n",
       "  'kinds',\n",
       "  'evidence',\n",
       "  'past',\n",
       "  'insects',\n",
       "  'ability',\n",
       "  'mice',\n",
       "  'eternity',\n",
       "  'mummification',\n",
       "  'mummify'],\n",
       " ['color',\n",
       "  'color',\n",
       "  'pattern',\n",
       "  'shape',\n",
       "  'eye',\n",
       "  'chocolate',\n",
       "  'prefer',\n",
       "  'coat',\n",
       "  'almond',\n",
       "  'apricot',\n",
       "  'green',\n",
       "  'fur',\n",
       "  'cream',\n",
       "  'cinnamon',\n",
       "  'lilac',\n",
       "  'fawn',\n",
       "  'tortoiseshell',\n",
       "  'caramel',\n",
       "  'tabby',\n",
       "  'longhairs'],\n",
       " ['day',\n",
       "  'day',\n",
       "  'artist',\n",
       "  'soul',\n",
       "  'label',\n",
       "  'album',\n",
       "  'debut',\n",
       "  'release',\n",
       "  'teenager',\n",
       "  'hop',\n",
       "  'record',\n",
       "  'title',\n",
       "  'hip',\n",
       "  'self',\n",
       "  'swing',\n",
       "  'studio'],\n",
       " ['create',\n",
       "  'create',\n",
       "  'municipalities',\n",
       "  'publish',\n",
       "  'office',\n",
       "  'access',\n",
       "  'municipality',\n",
       "  'merge'],\n",
       " ['humans',\n",
       "  'humans',\n",
       "  'treatment',\n",
       "  'lead',\n",
       "  'race',\n",
       "  'ethnicity',\n",
       "  'tie',\n",
       "  'link',\n",
       "  'racism',\n",
       "  'categories',\n",
       "  'categorize'],\n",
       " ['things',\n",
       "  'things',\n",
       "  'use',\n",
       "  'thing',\n",
       "  'ones',\n",
       "  'spell',\n",
       "  'experts',\n",
       "  'hello',\n",
       "  'adult',\n",
       "  'attention',\n",
       "  'noise',\n",
       "  'annoy',\n",
       "  'meow']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_topic_words_to_print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_output = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'sex',\n",
       " 'keep',\n",
       " 'breed',\n",
       " 'remove',\n",
       " 'organs',\n",
       " 'cat',\n",
       " 'leopard',\n",
       " 'pet',\n",
       " 'cheetah',\n",
       " 'felines',\n",
       " 'furry',\n",
       " 'hairless',\n",
       " 'jaguar',\n",
       " 'lynx',\n",
       " 'puma',\n",
       " 'pussycat',\n",
       " 'tame',\n",
       " 'wildcat',\n",
       " 'come',\n",
       " 'weight',\n",
       " 'flavor',\n",
       " 'food',\n",
       " 'vegetables',\n",
       " 'meat',\n",
       " 'feed',\n",
       " 'salmon',\n",
       " 'owners',\n",
       " 'milk',\n",
       " 'formulas',\n",
       " 'manufacture',\n",
       " 'bag',\n",
       " 'can',\n",
       " 'nutrient',\n",
       " 'essence',\n",
       " 'moist',\n",
       " 'diet',\n",
       " 'kitten',\n",
       " 'color',\n",
       " 'pattern',\n",
       " 'shape',\n",
       " 'eye',\n",
       " 'chocolate',\n",
       " 'prefer',\n",
       " 'coat',\n",
       " 'almond',\n",
       " 'apricot',\n",
       " 'green',\n",
       " 'fur',\n",
       " 'cream',\n",
       " 'cinnamon',\n",
       " 'lilac',\n",
       " 'fawn',\n",
       " 'tortoiseshell',\n",
       " 'caramel',\n",
       " 'tabby',\n",
       " 'longhairs',\n",
       " 'hunt',\n",
       " 'body',\n",
       " 'hole',\n",
       " 'domesticate',\n",
       " 'thin',\n",
       " 'rodent',\n",
       " 'rabbit',\n",
       " 'ferret',\n",
       " 'things',\n",
       " 'use',\n",
       " 'thing',\n",
       " 'ones',\n",
       " 'spell',\n",
       " 'experts',\n",
       " 'hello',\n",
       " 'adult',\n",
       " 'attention',\n",
       " 'noise',\n",
       " 'annoy',\n",
       " 'meow',\n",
       " 'create',\n",
       " 'municipalities',\n",
       " 'publish',\n",
       " 'office',\n",
       " 'access',\n",
       " 'municipality',\n",
       " 'merge',\n",
       " 'fall',\n",
       " 'mark',\n",
       " 'sense',\n",
       " 'protect',\n",
       " 'animals',\n",
       " 'live',\n",
       " 'list',\n",
       " 'learn',\n",
       " 'eat',\n",
       " 'tree',\n",
       " 'bird',\n",
       " 'range',\n",
       " 'stay',\n",
       " 'territory',\n",
       " 'genus',\n",
       " 'deal',\n",
       " 'catch',\n",
       " 'fast',\n",
       " 'jungle',\n",
       " 'report',\n",
       " 'monkey',\n",
       " 'jump',\n",
       " 'like',\n",
       " 'snake',\n",
       " 'concern',\n",
       " 'spray',\n",
       " 'dense',\n",
       " 'vegetation',\n",
       " 'swimmers',\n",
       " 'jungles',\n",
       " 'clumsy',\n",
       " 'ocelot',\n",
       " 'ocelots',\n",
       " 'people',\n",
       " 'ancient',\n",
       " 'scrap',\n",
       " 'foods',\n",
       " 'taste',\n",
       " 'today',\n",
       " 'rat',\n",
       " 'compare',\n",
       " 'ancestors',\n",
       " 'gods',\n",
       " 'kinds',\n",
       " 'evidence',\n",
       " 'past',\n",
       " 'insects',\n",
       " 'ability',\n",
       " 'mice',\n",
       " 'eternity',\n",
       " 'mummification',\n",
       " 'mummify',\n",
       " 'look',\n",
       " 'group',\n",
       " 'order',\n",
       " 'farm',\n",
       " 'grow',\n",
       " 'families',\n",
       " 'diverse',\n",
       " 'aquarium',\n",
       " 'whisker',\n",
       " 'barbel',\n",
       " 'catfish',\n",
       " 'classify',\n",
       " 'southeast',\n",
       " 'genera']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "wiki_topicmodel = Lda.load('models/180925_wikipedia_model.individually_binned.200.gensim.')\n",
    "\n",
    "# loading the stemmed_dict\n",
    "\n",
    "with open('180922_stemmed_dict.p', 'rb') as tounpick:\n",
    "    stemmed_dict = pickle.load(tounpick)\n",
    "\n",
    "# Loading the doc2vec\n",
    "\n",
    "wiki_doc2vec = doc2vec.Doc2Vec.load('models/simple_wiki_chunked_doc2vec_300_vector_10_min_word')\n",
    "\n",
    "# loading the doc2vec corpus \n",
    "\n",
    "with open('models/simple_wiki_chunked_corpus_10_count_cutoff.p', 'rb') as tounpcik:\n",
    "    wiki_doc2vec_corpus = pickle.load(tounpcik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with words from topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_top_topics(topic_list, model, min_topic_prob=0.1, min_word_prob=0.05):\n",
    "    \"\"\"\n",
    "    First finding all of the words\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_words = []\n",
    "    \n",
    "    topic_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    for topic, topic_prob in topic_list:\n",
    "        \n",
    "        if topic_prob < min_topic_prob:\n",
    "            break\n",
    "        \n",
    "        for word_id, word_prob in model.get_topic_terms(topic, 100):\n",
    "            if word_prob < min_word_prob:\n",
    "                break\n",
    "            list_of_words.append(model.id2word[word_id])\n",
    "    \n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_top_topic(topic_list, model, min_word_prob=0.05):\n",
    "    \"\"\"\n",
    "    First finding all of the words\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_words = []\n",
    "    topic_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    \n",
    "    topic, topic_prob = topic_list[0]\n",
    "        \n",
    "    for word_id, word_prob in model.get_topic_terms(topic, 100):\n",
    "        if word_prob < min_word_prob:\n",
    "            break\n",
    "        if model.id2word[word_id] in stemmed_dict:\n",
    "            for word in stemmed_dict[model.id2word[word_id]]:\n",
    "                list_of_words.append(word)\n",
    "        else:\n",
    "            list_of_words.append(model.id2word[word_id])\n",
    "\n",
    "    \n",
    "    return list_of_words, topic_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the context\n",
    "\n",
    "context = 'purr'\n",
    "context = \"Climbing is the activity of using one's hands, feet, or any other part of the body to ascend a steep object. It is done for locomotion, recreation and competition, in trades that rely on it, and in emergency rescue and military operations. It is done indoors and out, on natural and man-made structures.\"\n",
    "# context = \"The domestic cat (Felis silvestris catus or Felis catus)[1][4] is a small, typically furry, carnivorous mammal. They are often called house cats[5] when kept as indoor pets or simply cats when there is no need to distinguish them from other felids and felines. They are often valued by humans for companionship and for their ability to hunt vermin. There are more than seventy cat breeds recognized by various cat registries.\"\n",
    "\n",
    "# Tokenize context \n",
    "\n",
    "context_tokens = pun.tokenize(context)\n",
    "\n",
    "# Convert to bow\n",
    "\n",
    "bag_of_words = wiki_topicmodel.id2word.doc2bow(context_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_topicmodel_words(sentence, model):\n",
    "    context_tokens = pun.tokenize(sentence)\n",
    "    bag_of_words = model.id2word.doc2bow(context_tokens)\n",
    "    document_topics = model.get_document_topics(bag_of_words) \n",
    "    return get_words_from_top_topic(document_topics, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['wear', 'feet', 'walk'], 0.12638511)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_topicmodel_words(context, wiki_topicmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with doc2vec information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_doc2vec(text, model):\n",
    "    \"\"\"\n",
    "    Iterator which spits out words that are found in \n",
    "    the most 'topical' textual elements\n",
    "    \"\"\"\n",
    "    # parse the sentence \n",
    "    text = simple_preprocess(text)\n",
    "    # Find the respective doc2vec vector\n",
    "    text_vector = model.infer_vector(text)\n",
    "    # find the most similar text pieces\n",
    "    most_similar_documents_with_score = model.docvecs.most_similar([text_vector])\n",
    "    \n",
    "    for document_id, cosine_sim_score in most_similar_documents_with_score:\n",
    "        \n",
    "        yield (set(pun.tokenize(wiki_doc2vec_corpus[document_id], stem=False, initial_word_split=False)), cosine_sim_score)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sentence_to_doc2vec(\"Climbing is the activity of using one's hands, feet, or any other part of the body to ascend a steep object. It is done for locomotion, recreation and competition, in trades that rely on it, and in emergency rescue and military operations. It is done indoors and out, on natural and man-made structures.\",\n",
    "                             wiki_doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sentence_to_doc2vec at 0x7f62a6ff61a8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmvoje/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'examples',\n",
       "  'harm',\n",
       "  'include',\n",
       "  'inhibition',\n",
       "  'organism',\n",
       "  'plant',\n",
       "  'relationship',\n",
       "  'secretions',\n",
       "  'shade',\n",
       "  'taller',\n",
       "  'wider'},\n",
       " 0.36731237173080444)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builiding how it is all connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_possible_pun_substitutions(context, input_sentence, w2v_number=4):\n",
    "    \"\"\"\n",
    "    Takes context and input sentence \n",
    "    \n",
    "    returns list of possible substitutions with scores and the topic \n",
    "    words consdiered\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # First process context\n",
    "    doc2vec_word_generator = sentence_to_doc2vec(context, wiki_doc2vec)\n",
    "    topic_words, topic_score = sentence_to_topicmodel_words(context, wiki_topicmodel)\n",
    "\n",
    "    # Then try to generate sentences using these metrics\n",
    "    output = []\n",
    "    topic_words_considered = []\n",
    "    \n",
    "    # consider word2vec words\n",
    "    for i in range(w2v_number):\n",
    "        words, w2v_score = next(doc2vec_word_generator)\n",
    "\n",
    "        topic_words_considered.extend([[word, 'doc2vec', i+1, w2v_score] for word in words])\n",
    "\n",
    "        sub_tuples = pun.enumerate_PD_pun_subs(input_sentence, words)\n",
    "        # word, sub_index, phonetic_distance\n",
    "\n",
    "        for word, sub_index, phon_dist in sub_tuples:\n",
    "            output.append([word, sub_index, phon_dist, 'doc2vec', i+1, w2v_score, phon_dist/w2v_score])\n",
    "\n",
    "    # Now do topic words\n",
    "    sub_tuples = pun.enumerate_PD_pun_subs(input_sentence, topic_words)\n",
    "    for word, sub_index, phon_dist in sub_tuples:\n",
    "\n",
    "        topic_words_considered.append([word, 'topicModel', 1, topic_score])\n",
    "\n",
    "        output.append([word, sub_index, phon_dist, 'topicModel', 1, topic_score, phon_dist/topic_score])\n",
    "\n",
    "    output.sort(key=lambda x: x[6])\n",
    "    \n",
    "    return output, topic_words_considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = \"Climbing is the activity of using one's hands, feet, or any other part of the body to ascend a steep object. It is done for locomotion, recreation and competition, in trades that rely on it, and in emergency rescue and military operations. It is done indoors and out, on natural and man-made structures.\"\n",
    "context = \"Prince of the United Kingdom of Great Britain and Northern Ireland is a royal title normally granted to sons and grandsons of reigning and past British monarchs. It is also held by the Duke of Edinburgh, husband and consort of Queen Elizabeth II. The title is granted by the reigning monarch, who is the fount of all honours, through the issuing of letters patent as an expression of the royal will.\"\n",
    "\n",
    "input_sentence = \"join us at our gym we hope to see you there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wmvoje/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "ranked_substitutions, topic_words_considered = generate_possible_pun_substitutions(context, input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "join us at flower gym we hope to see you there\n",
      "join us at our gym we hope to see use there\n",
      "join us at our gym we hope to see you wear\n",
      "join us at our gym we hope to sir you there\n",
      "join us at our gym see hope to see you there\n",
      "join us at our gym way hope to see you there\n",
      "join use at our gym we hope to see you there\n",
      "join us at our gym queen hope to see you there\n",
      "join sir at our gym we hope to see you there\n",
      "join pass at our gym we hope to see you there\n"
     ]
    }
   ],
   "source": [
    "for thing in [pun.substitute_pun(input_sentence, x[:3]) for x in ranked_substitutions[:10]]:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['flower', 3, 2, 'doc2vec', 1, 0.7421815395355225, 2.6947584835533025],\n",
       " ['use', 9, 2, 'doc2vec', 1, 0.7421815395355225, 2.6947584835533025],\n",
       " ['wear', 10, 2, 'doc2vec', 1, 0.7421815395355225, 2.6947584835533025],\n",
       " ['sir', 8, 2, 'doc2vec', 2, 0.7250586152076721, 2.758397677168704],\n",
       " ['see', 5, 2, 'doc2vec', 3, 0.7234101295471191, 2.764683432414849],\n",
       " ['way', 5, 2, 'doc2vec', 3, 0.7234101295471191, 2.764683432414849],\n",
       " ['use', 1, 3, 'doc2vec', 1, 0.7421815395355225, 4.042137725329954],\n",
       " ['queen', 5, 3, 'doc2vec', 1, 0.7421815395355225, 4.042137725329954],\n",
       " ['sir', 1, 3, 'doc2vec', 2, 0.7250586152076721, 4.1375965157530565],\n",
       " ['pass', 1, 3, 'doc2vec', 2, 0.7250586152076721, 4.1375965157530565],\n",
       " ['man', 2, 3, 'doc2vec', 2, 0.7250586152076721, 4.1375965157530565],\n",
       " ['pass', 2, 3, 'doc2vec', 2, 0.7250586152076721, 4.1375965157530565],\n",
       " ['knight', 2, 3, 'doc2vec', 2, 0.7250586152076721, 4.1375965157530565],\n",
       " ['see', 1, 3, 'doc2vec', 3, 0.7234101295471191, 4.147025148622274],\n",
       " ['pass', 1, 3, 'doc2vec', 3, 0.7234101295471191, 4.147025148622274],\n",
       " ['base', 1, 3, 'doc2vec', 3, 0.7234101295471191, 4.147025148622274],\n",
       " ['pass', 2, 3, 'doc2vec', 3, 0.7234101295471191, 4.147025148622274],\n",
       " ['past', 2, 3, 'doc2vec', 3, 0.7234101295471191, 4.147025148622274],\n",
       " ['house', 1, 3, 'doc2vec', 4, 0.7207200527191162, 4.162503858025968],\n",
       " ['coat', 2, 3, 'doc2vec', 4, 0.7207200527191162, 4.162503858025968],\n",
       " ['house', 3, 3, 'doc2vec', 4, 0.7207200527191162, 4.162503858025968],\n",
       " ['chain', 0, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['win', 0, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['dance', 1, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['part', 2, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['crown', 3, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['win', 4, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['king', 4, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['win', 5, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['wear', 5, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['head', 6, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['type', 6, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['use', 7, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['choose', 7, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['type', 7, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['use', 8, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['receive', 8, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['choose', 9, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['head', 10, 4, 'doc2vec', 1, 0.7421815395355225, 5.389516967106605],\n",
       " ['man', 0, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['sir', 2, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['sir', 3, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['order', 3, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['sir', 5, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['sir', 7, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['knight', 7, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['pass', 8, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['sir', 9, 4, 'doc2vec', 2, 0.7250586152076721, 5.516795354337408],\n",
       " ['know', 0, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 1, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 1, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['way', 1, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 1, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['see', 2, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 2, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['quit', 2, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 2, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['way', 2, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 2, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['see', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['crown', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['way', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['order', 3, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['time', 4, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['king', 4, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 5, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 5, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 5, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 6, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['see', 7, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 7, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['time', 7, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 7, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['way', 7, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 7, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['pass', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['past', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['way', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['base', 8, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['see', 9, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['law', 9, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['know', 9, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['way', 9, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['die', 9, 4, 'doc2vec', 3, 0.7234101295471191, 5.529366864829698],\n",
       " ['earl', 1, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['earl', 2, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['earl', 3, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['arm', 4, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['give', 4, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['peer', 4, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['earl', 5, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['coat', 6, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['house', 6, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['coat', 7, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['duke', 7, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['earl', 7, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['house', 8, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['earl', 8, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['duke', 9, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['earl', 9, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['peer', 10, 4, 'doc2vec', 4, 0.7207200527191162, 5.550005144034624],\n",
       " ['white', 2, 3, 'topicModel', 1, 0.18716377, 16.02874315265787],\n",
       " ['marie', 5, 3, 'topicModel', 1, 0.18716377, 16.02874315265787],\n",
       " ['marie', 8, 3, 'topicModel', 1, 0.18716377, 16.02874315265787],\n",
       " ['louis', 1, 4, 'topicModel', 1, 0.18716377, 21.371657536877162],\n",
       " ['marie', 3, 4, 'topicModel', 1, 0.18716377, 21.371657536877162],\n",
       " ['white', 5, 4, 'topicModel', 1, 0.18716377, 21.371657536877162],\n",
       " ['white', 7, 4, 'topicModel', 1, 0.18716377, 21.371657536877162],\n",
       " ['mary', 10, 4, 'topicModel', 1, 0.18716377, 21.371657536877162]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['prize', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['use', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['monarchy', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['head', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['chain', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['choose', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['receive', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['crown', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['queen', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['win', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['example', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['couple', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['monarch', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['girl', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['winners', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['flower', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['dance', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['contest', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['pageant', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['occasion', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['call', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['headdress', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['nothing', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['symbol', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['king', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['wear', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['part', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['award', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['type', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['daisy', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['beauty', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['children', 'doc2vec', 1, 0.7421815395355225],\n",
       " ['chivalry', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['title', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['rank', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['members', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['baronets', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['sir', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['barons', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['kingdom', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['baronet', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['order', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['bachelor', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['man', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['pass', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['children', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['knight', 'doc2vec', 2, 0.7250586152076721],\n",
       " ['sister', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['primogeniture', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['inheritance', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['monarchy', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['see', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['pass', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['child', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['cousin', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['throne', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['question', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['oldest', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['command', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['law', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['crown', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['quit', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['create', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['beforehand', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['monarch', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['family', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['time', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['monarchies', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['know', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['monarchs', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['idea', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['system', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['member', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['past', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['king', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['arrange', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['way', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['nowadays', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['methods', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['die', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['succession', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['brother', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['order', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['base', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['children', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['loyalty', 'doc2vec', 3, 0.7234101295471191],\n",
       " ['ceremonies', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['college', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['charge', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['lord', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['arm', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['household', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['give', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['coat', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['house', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['marshal', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['duke', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['hereditary', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['peer', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['earl', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['permission', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['elect', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['issue', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['royal', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['member', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['processions', 'doc2vec', 4, 0.7207200527191162],\n",
       " ['white', 'topicModel', 1, 0.18716377],\n",
       " ['marie', 'topicModel', 1, 0.18716377],\n",
       " ['marie', 'topicModel', 1, 0.18716377],\n",
       " ['louis', 'topicModel', 1, 0.18716377],\n",
       " ['marie', 'topicModel', 1, 0.18716377],\n",
       " ['white', 'topicModel', 1, 0.18716377],\n",
       " ['white', 'topicModel', 1, 0.18716377],\n",
       " ['mary', 'topicModel', 1, 0.18716377]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words_considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_topic_words_to_print(topic_words):\n",
    "    output = [[]]\n",
    "    topic_number = 1\n",
    "    for topic in topic_words:\n",
    "        if topic[1] == 'topicModel':\n",
    "            return output\n",
    "        if topic[2] != topic_number:\n",
    "            topic_number = topic[2]\n",
    "            output.append([topic[0]])\n",
    "        output[topic_number-1].append(topic[0])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['prize',\n",
       "  'use',\n",
       "  'monarchy',\n",
       "  'head',\n",
       "  'chain',\n",
       "  'choose',\n",
       "  'receive',\n",
       "  'crown',\n",
       "  'queen',\n",
       "  'win',\n",
       "  'example',\n",
       "  'couple',\n",
       "  'monarch',\n",
       "  'girl',\n",
       "  'winners',\n",
       "  'flower',\n",
       "  'dance',\n",
       "  'contest',\n",
       "  'pageant',\n",
       "  'occasion',\n",
       "  'call',\n",
       "  'headdress',\n",
       "  'nothing',\n",
       "  'symbol',\n",
       "  'king',\n",
       "  'wear',\n",
       "  'part',\n",
       "  'award',\n",
       "  'type',\n",
       "  'daisy',\n",
       "  'beauty',\n",
       "  'children'],\n",
       " ['chivalry',\n",
       "  'chivalry',\n",
       "  'title',\n",
       "  'rank',\n",
       "  'members',\n",
       "  'baronets',\n",
       "  'sir',\n",
       "  'barons',\n",
       "  'kingdom',\n",
       "  'baronet',\n",
       "  'order',\n",
       "  'bachelor',\n",
       "  'man',\n",
       "  'pass',\n",
       "  'children',\n",
       "  'knight'],\n",
       " ['sister',\n",
       "  'sister',\n",
       "  'primogeniture',\n",
       "  'inheritance',\n",
       "  'monarchy',\n",
       "  'see',\n",
       "  'pass',\n",
       "  'child',\n",
       "  'cousin',\n",
       "  'throne',\n",
       "  'question',\n",
       "  'oldest',\n",
       "  'command',\n",
       "  'law',\n",
       "  'crown',\n",
       "  'quit',\n",
       "  'create',\n",
       "  'beforehand',\n",
       "  'monarch',\n",
       "  'family',\n",
       "  'time',\n",
       "  'monarchies',\n",
       "  'know',\n",
       "  'monarchs',\n",
       "  'idea',\n",
       "  'system',\n",
       "  'member',\n",
       "  'past',\n",
       "  'king',\n",
       "  'arrange',\n",
       "  'way',\n",
       "  'nowadays',\n",
       "  'methods',\n",
       "  'die',\n",
       "  'succession',\n",
       "  'brother',\n",
       "  'order',\n",
       "  'base',\n",
       "  'children',\n",
       "  'loyalty'],\n",
       " ['ceremonies',\n",
       "  'ceremonies',\n",
       "  'college',\n",
       "  'charge',\n",
       "  'lord',\n",
       "  'arm',\n",
       "  'household',\n",
       "  'give',\n",
       "  'coat',\n",
       "  'house',\n",
       "  'marshal',\n",
       "  'duke',\n",
       "  'hereditary',\n",
       "  'peer',\n",
       "  'earl',\n",
       "  'permission',\n",
       "  'elect',\n",
       "  'issue',\n",
       "  'royal',\n",
       "  'member',\n",
       "  'processions']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_topic_words_to_print(topic_words_considered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [pun.tokenize(thing, stem=False, initial_word_split=False) for thing in wiki_doc2vec_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'year',\n",
       " 'come',\n",
       " 'march',\n",
       " 'months',\n",
       " 'day',\n",
       " 'begin',\n",
       " 'day',\n",
       " 'week',\n",
       " 'years',\n",
       " 'end',\n",
       " 'day',\n",
       " 'week',\n",
       " 'flower',\n",
       " 'daisy',\n",
       " 'birthstone',\n",
       " 'diamond',\n",
       " 'mean',\n",
       " 'diamond',\n",
       " 'innocence']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = Dictionary(tokenized_corpus)  # fit dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(line) for line in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152497"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct.save('models/TF-IDF_dict.D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model[corpus[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "gensim.utils.SaveLoad.save()\n",
    "with open('models/TF-IDF_corpus.p', 'wb') as topick:\n",
    "    pickle.dump(corpus, topick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 0.07642991265596688\n",
      "come 0.09299847380709479\n",
      "number 0.10308215631069341\n",
      "end 0.10333525130180589\n",
      "days 0.13522422413363386\n",
      "august 0.1449337374796481\n",
      "emperor 0.16665567988985144\n",
      "begin 0.19614152904365406\n",
      "calendar 0.20515363602679768\n",
      "year 0.28992506519039224\n",
      "day 0.4491260326768479\n",
      "week 0.5080217645940343\n",
      "month 0.5222296322234486\n"
     ]
    }
   ],
   "source": [
    "test = model[corpus[2]]\n",
    "\n",
    "test.sort(key=lambda x: x[1])\n",
    "\n",
    "for word, score in test:\n",
    "    print(dct.id2token[word], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 0.07642991265596688),\n",
       " (2, 0.09299847380709479),\n",
       " (50, 0.10308215631069341),\n",
       " (6, 0.10333525130180589),\n",
       " (21, 0.13522422413363386),\n",
       " (48, 0.1449337374796481),\n",
       " (49, 0.16665567988985144),\n",
       " (0, 0.19614152904365406),\n",
       " (17, 0.20515363602679768),\n",
       " (14, 0.28992506519039224),\n",
       " (4, 0.4491260326768479),\n",
       " (13, 0.5080217645940343),\n",
       " (11, 0.5222296322234486)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build 0.12450906492301654\n",
      "church 0.16052042249390314\n",
      "road 0.18368004313367003\n",
      "market 0.19754512702055013\n",
      "square 0.20926182074280714\n",
      "edge 0.218723944519035\n",
      "ruin 0.25152988694747286\n",
      "hall 0.36196445127489196\n",
      "pannier 0.507616944545011\n",
      "town 0.5851299576409561\n"
     ]
    }
   ],
   "source": [
    "test = model[corp]\n",
    "\n",
    "test.sort(key=lambda x: x[1])\n",
    "\n",
    "for word, score in test:\n",
    "    print(dct.id2token[word], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/TF-IDF_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 3),\n",
       " (5, 2),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 2),\n",
       " (14, 1),\n",
       " (15, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow(tokenized_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'begin'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.id2token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_of_document(document_id, model, dictionary, corpus, tf_idf_cutoff=0.07):\n",
    "    \n",
    "    # get the tf idf from the document id\n",
    "    tf_idf = model[corpus[document_id]]\n",
    "#     tf_idf.sort(key=lambda x: x[1])\n",
    "    \n",
    "    output = []\n",
    "    tf_idf_value = None\n",
    "    for index, tf_idf_value in tf_idf:\n",
    "        if tf_idf_value > tf_idf_cutoff:\n",
    "            output.append((dictionary.id2token[index], tf_idf_value))\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('come', 0.10673392377531137),\n",
       " ('day', 0.28994619210772093),\n",
       " ('march', 0.10383883276298947),\n",
       " ('month', 0.34962699596013763),\n",
       " ('week', 0.4372906947713977),\n",
       " ('year', 0.5545761226284901),\n",
       " ('years', 0.33699147777144156),\n",
       " ('celebrate', 0.15798987865350744),\n",
       " ('culture', 0.08404457453076937),\n",
       " ('days', 0.07759811231522494),\n",
       " ('fall', 0.0803843363913717),\n",
       " ('finish', 0.13069831455488717),\n",
       " ('follow', 0.0960991206553891),\n",
       " ('quite', 0.08402694480854042),\n",
       " ('spring', 0.09459211153512359),\n",
       " ('start', 0.10380382878112404),\n",
       " ('theory', 0.09507702380831191)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_of_document(1, model, dct, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_of_words = [word[0] for word in topic_words_considered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('choose', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pun.pos_tag(['choose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. right topic \n",
    "2. Does it sound similar \n",
    "\n",
    "implement live validation *********\n",
    "\n",
    "Conversational corpus \n",
    "\n",
    "multi-arm banding \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
